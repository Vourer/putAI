{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JuhN1KUAkk1"
      },
      "source": [
        "## Zaawansowane Metody Inteligencji Obliczeniowej\n",
        "# Zadanie domowe 1\n",
        "### Prowadzący: Michał Kempka, Marek Wydmuch\n",
        "### Autor: Adam Marciniak + 141273"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsBejzJ9Akk5"
      },
      "source": [
        "## Wprowadzenie\n",
        "\n",
        "Całe zadanie jest oparte o różne wersje środowiska `VacuumEnvironemnt`, które rozważaliśmy na zajęciach.\n",
        "Środowisko zaimplementowane jest w bibliotece aima3 (https://github.com/ArtificialIntelligenceToolkit/aima3),\n",
        "która zawiera kod do książki \"Artificial Intelligence: A Modern Approach\".\n",
        "\n",
        "#### Uwaga: Możesz dowolnie modyfikować elementy tego notebooka (wstawiać komórki i zmieniać kod) o ile nie napisano gdzieś inaczej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lCjhpMFAkk7",
        "outputId": "ec8784db-b5fe-4bcf-e1cc-c87bc78d07cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 150 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 60.7 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.18.3 requires networkx>=2.0, but you have networkx 1.11 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Zainstaluj bibliotekę OpenAI Gym\n",
        "!pip install aima3 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c4LovjXjAkk8"
      },
      "outputs": [],
      "source": [
        "# Zaimportuj wszystkie jego elementy\n",
        "from aima3.agents import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ul4bzatAkk9"
      },
      "source": [
        "Wszystkie używane przez nas elementy biblioteki są zaimplementowane w pliku: https://github.com/ArtificialIntelligenceToolkit/aima3/blob/master/aima3/agents.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8JT05m5Akk9"
      },
      "source": [
        "# Zad. 1 - Cechy środowiska odkurzacza (1 pkt.)\n",
        "\n",
        "Wypisz cechy poniżej używanego środowiska zgodnie z klasyfikacją z wykładu 1.\n",
        "Dla ciągłości/dyskretności określ cechy osobno w stosunku do czasu, akcji i przestrzeni stanów.\n",
        "W razie wątpliwości uzasadnij swój wybór.\n",
        "\n",
        "Odpowiedź:\n",
        "Środowisko to jest:\n",
        "- Częściowo obserwowalne - stan obecnego pokoju jest znany, ale nie wiemy, co jest w drugim.\n",
        "- Jednoagentowe.\n",
        "- Deterministyczne.\n",
        "- Dyskretne:\n",
        "  * mamy skończoną ilość czasu/kroków (środowisko kończy się po `x` krokach);\n",
        "  * są tylko 4 możliwe akcje: {suck, left, right, noop};\n",
        "  * jest tylko 8 możliwych kombinacji stanów (2 dla każdego pokoju: {dirty, clean} oraz 2 dla agenta: {left, right}).\n",
        "- Model środowiska jest znany.\n",
        "\n",
        "Tip: Możesz sprawdź implementacje środowiska w pliku podanym powyżej, lub wywnioskować cechy na wykonując poniższe fragmenty kodu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JWEoiGRJAkk-"
      },
      "outputs": [],
      "source": [
        "# Stwórz nowe środowisko świata odkurzacza\n",
        "env = TrivialVacuumEnvironment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFdZYD9iAkk_",
        "outputId": "b4150aba-217e-4b88-c09c-7b531344ad2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0): 'Clean', (1, 0): 'Clean'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Sprawdź aktualny status środowiska\n",
        "env.status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWcs7luNAklA",
        "outputId": "40832aac-ee39-49b1-8a47-a0e4e0fbd681"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Utwórz agenta refleksyjnego\n",
        "agent = ReflexVacuumAgent()\n",
        "agent.is_alive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XL6TFE5nAklB"
      },
      "outputs": [],
      "source": [
        "# Dodaj agenta do środowiska. Owijamy go w TraceAgent'a, żeby zobaczyć co robi.\n",
        "env.add_thing(TraceAgent(agent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpY1gPuAAklB",
        "outputId": "ee42ea92-1a5c-4745-8ecc-1c473f166f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loc (0, 0): []\n",
            "loc (1, 0): [<Agent>]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Zobacz gdzie jest agent\n",
        "for loc in [loc_A, loc_B]:\n",
        "    print('loc {0}: {1}'.format(loc, env.list_things_at(loc)))\n",
        "# Lub:\n",
        "agent.location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfWtEAG7AklC",
        "outputId": "792d332f-9d59-4b56-a1ab-ec342ff1e26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Agent> perceives ((1, 0), 'Clean') and does Left\n",
            "<Agent> perceives ((0, 0), 'Clean') and does Right\n",
            "<Agent> perceives ((1, 0), 'Clean') and does Left\n",
            "<Agent> perceives ((0, 0), 'Clean') and does Right\n",
            "<Agent> perceives ((1, 0), 'Clean') and does Left\n",
            "<Agent> perceives ((0, 0), 'Clean') and does Right\n",
            "<Agent> perceives ((1, 0), 'Clean') and does Left\n",
            "<Agent> perceives ((0, 0), 'Clean') and does Right\n",
            "<Agent> perceives ((1, 0), 'Clean') and does Left\n",
            "<Agent> perceives ((0, 0), 'Clean') and does Right\n"
          ]
        }
      ],
      "source": [
        "# Wykonaj 10 kroków\n",
        "env.run(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YmmQJ5FAklC",
        "outputId": "dbeaf7cd-3703-45a8-aa43-ace788378cc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-10"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Sprawdź jak środowisko oceniło jakość agenta.\n",
        "agent.performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbT8GtBLAklD",
        "outputId": "a12938c5-3477-4258-a0c0-44447cdded6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<function aima3.agents.ReflexVacuumAgent>, -38.824),\n",
              " (<function aima3.agents.ModelBasedVacuumAgent>, 9.16)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Moglibyśmy ocenić oczekiwaną jakość agenta dokładniej..., ale tylko ją oszacujemy (1000 powtórzeń).\n",
        "# Zakładamy, że symulacja trwa 50 kroków.\n",
        "\n",
        "compare_agents(TrivialVacuumEnvironment, [ReflexVacuumAgent, ModelBasedVacuumAgent], 1000, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBDNAoQwAklD"
      },
      "source": [
        "# Zad. 2 - Cechy zmodyfikowanego środowisko odkurzacza (1 pkt).\n",
        "\n",
        "Wypisz cechy poniżej używanego środowiska zgodnie z klasyfikacją z wykładu 1.\n",
        "Dla ciągłości/dyskretności określ cechy osobno w stosunku do czasu, akcji i przestrzeni stanów.\n",
        "W razie wątpliwości uzasadnij swój wybór.\n",
        "\n",
        "Odpowiedź:\n",
        "Środowisko to jest:\n",
        "- Częściowo obserwowalne - stan obecnego pokoju jest znany, ale nie wiemy, co jest w drugim.\n",
        "- Jednoagentowe.\n",
        "- Stochastyczne - z jednej strony za każdą akcję Agent zawsze dostanie tę samą karę lub nagrodę (determinizm), ale z drugiej strony losowa szansa na zabrudzenie sprawia, że ta sama akcja może doprowadzić do różnych stanów. Może na przykład dojść do sytuacji, w której Agent wyczyści pokój, ale w następnym kroku zaobserwuje, że pokój nadal jest brudny, mimo że powinien być czysty. Agent może też czekać przez parę kroków w czystym pokoju i raz zaobserwować pokój czysty, a innym razem brudny.\n",
        "- Dyskretne:\n",
        "  * nadal mamy skończoną ilość czasu/kroków (środowisko kończy się po `x` krokach);\n",
        "  * nadal są tylko 4 możliwe akcje: {suck, left, right, noop}, chociaż tym razem mogą prowadzić do różnych stanów;\n",
        "  * nadal jest tylko 8 możliwych kombinacji stanów (2 dla każdego pokoju: {dirty, clean} oraz 2 dla agenta: {left, right}).\n",
        "- Model środowiska jest znany - znamy prawdopodobieństwo ponownego zabrudzenia, a tym samym rozkład prawdopodobieństw konsekwencji akcji Agenta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_b_g171zAklD"
      },
      "outputs": [],
      "source": [
        "# Rozszerzmy implementacje TrivialVacuumEnvironment\n",
        "\n",
        "import random\n",
        "\n",
        "class TrivialVacuumEnvironmentWithCats(TrivialVacuumEnvironment):\n",
        "    def __init__(self, random_dirt_prob=0.05, seed=None):\n",
        "        super(TrivialVacuumEnvironmentWithCats, self).__init__()\n",
        "        self.random = random.Random(seed)\n",
        "        self.random_dirt_prob = random_dirt_prob\n",
        "\n",
        "    def execute_action(self, agent, action):\n",
        "        \"\"\"Change agent's location and/or location's status; track performance; add dirt;\n",
        "        Score 10 for each dirt cleaned; -1 for each move.\"\"\"\n",
        "        # Same as in case of TrivialVacuumEnvironment\n",
        "        if action == 'Right':\n",
        "            agent.location = loc_B\n",
        "            agent.performance -= 1\n",
        "        elif action == 'Left':\n",
        "            agent.location = loc_A\n",
        "            agent.performance -= 1\n",
        "        elif action == 'Suck':\n",
        "            if self.status[agent.location] == 'Dirty':\n",
        "                agent.performance += 10\n",
        "            self.status[agent.location] = 'Clean'\n",
        "\n",
        "        # Cats can make either location dirty\n",
        "        for loc in [loc_A, loc_B]:\n",
        "            if self.random.random() < self.random_dirt_prob:\n",
        "                self.status[loc] = 'Dirty'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjXrJDvUAklE",
        "outputId": "90902f59-e6f7-483b-c115-f1f9db836874"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<function aima3.agents.ReflexVacuumAgent>, 13.415),\n",
              " (<function aima3.agents.ModelBasedVacuumAgent>, 33.71)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Przetestujmy domyślnych agentów w nowym środowisku\n",
        "\n",
        "def env_factory():\n",
        "    return TrivialVacuumEnvironmentWithCats(random_dirt_prob=0.05)\n",
        "\n",
        "compare_agents(env_factory, [ReflexVacuumAgent, ModelBasedVacuumAgent], 1000, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9HUy-uhAklE"
      },
      "source": [
        "# Zad. 3 - Własny program agenta (8 pkt.)\n",
        "\n",
        "Napisz program agenta, który będzie (średnio) dużo lepszy dla tego środowiska (50 kroków, z random_dirt_prob=0.05) niż ModelBaseVacuumAgent oraz ReflexVacuumAgent. Opisz działanie swojego programu, na podstawie jaki przesłanek on działa, jakbyś go zmodyfikował gdyby prawdopodobieństwo zabrudzenia pokoju (random_dirt_prob) się zmieniło?\n",
        "\n",
        "Punktacja za wynik (sprawdzarka zrobi 50000 powtórzeń):\n",
        "* \\> 41: 1 pkt.\n",
        "* \\> 42: 2 pkt.\n",
        "* \\> 43: 3 pkt.\n",
        "* \\> 44: 4 pkt.\n",
        "* \\> 45: 5 pkt.\n",
        "* \\> 46: 6 pkt.\n",
        "\n",
        "\\+ 2 pkt. za opis.\n",
        "\n",
        "#### Uwaga: nie zmieniaj nazwy klasy `MyVacuumAgent`. Nie dopisuj do komórki z klasą innego kodu. Możesz zdefiniować funkcje pomocnicze w tej samej komórce (sprawdzarka wyciągnie ze zgłoszonego notebooka wyłącznie komórkę z klasę o nazwie `MyVacuumAgent` do sprawdzenia)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FwY1aw4WAklE"
      },
      "outputs": [],
      "source": [
        "# Klasa MyVacuumAgent wypełniona przykładowym kodem agenta z modelem\n",
        "\n",
        "def MyVacuumAgent():\n",
        "    random_dirt_prob = 0.05\n",
        "    moves_left = 50\n",
        "    time_since_jump = 50\n",
        "\n",
        "    def calc_chance(p, T):\n",
        "        # calculate the chance of cats making mess in the other room \n",
        "        chance = 0\n",
        "        for i in range(T):\n",
        "            chance += p * (1-p)**(i-1)\n",
        "        return chance\n",
        "\n",
        "    def program(percept):\n",
        "        nonlocal random_dirt_prob\n",
        "        nonlocal moves_left\n",
        "        nonlocal time_since_jump\n",
        "        moves_left -= 1\n",
        "        time_since_jump += 1\n",
        "        dirty_chance = calc_chance(random_dirt_prob, time_since_jump)\n",
        "\n",
        "        location, status = percept\n",
        "\n",
        "        if status == 'Dirty':\n",
        "            return 'Suck'\n",
        "        elif (moves_left == 0):\n",
        "            return 'NoOP'\n",
        "        elif (dirty_chance > 0.4) or (moves_left == 1 and dirty_chance > 0.2):\n",
        "            time_since_jump = 0\n",
        "            if location == loc_A:\n",
        "                return 'Right'\n",
        "            elif location == loc_B:\n",
        "                return 'Left'\n",
        "        else:\n",
        "            return 'NoOP'\n",
        "        \n",
        "    return Agent(program)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "W każdym kroku Agent oblicza sobie prawdopodobieństwo `dirty_chance`, z jakim może zastać bałagan po wykonaniu przejścia do innego pokoju. Do obliczeń wykorzystuje wartość prawdopodobieństwa `random_dirt_prob` oraz ilość kroków, która minęła od ostatnich odwiedzin tego pokoju - `time_since_jump`.\n",
        "\n",
        "Początkowo Agent przechodził do drugiego pokoju po tym, jak wyliczona szansa przekraczała **50%**, jednak kiedy zdałem sobie sprawę, że czeka w takim przypadku około 13 kroków w jednym pokoju, postanowiłem obniżyć ten próg do **40%** (10 kroków). Oprócz tego, jeżeli agent wykonuje właśnie swoją przedostatnią rundę (pozostała mu jeszcze jedna), to może przejść do drugiego pokoju, jeżeli szansa na zastanie bałaganu wynosi więcej niż **20%** (5 kroków), żeby w swojej ostatniej turze spróbować posprzątać ewentualny bałagan. Agent nie może przejść do drugiego pokoju w przypadku, kiedy wykonuje właśnie swój ostatni ruch - środowisko zakończy się w następnym kroku, więc Agent i tak nie zdąży już posprzątać drugiego pokoju.\n",
        "\n",
        "Nawet gdyby prawdopodobieństwo `random_dirt_prob` się zmieniło, wydaje mi się że Agent powinien nadal otrzymywać w miarę dobre wyniki bez wprowadzania dodatkwoych zmian. Gdyby kara za przechodzenie do drugiego pokoju wzrosła jakoś znacząco, pewnie podniósłbym odpowiednio progi procentowe. Gdyby zmniejszyła się ilość ruchów, zastanowiłbym się z kolei nad drobnym obniżeniem tych progów."
      ],
      "metadata": {
        "id": "fLu9r9w3xD5k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcK1GTZ_AklF",
        "outputId": "d99755b6-3c2d-4402-d212-31d1e3f7c245"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<function __main__.MyVacuumAgent>, 46.5543)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Przetestuj swojego agenta\n",
        "def env_factory():\n",
        "    return TrivialVacuumEnvironmentWithCats(random_dirt_prob=0.05)\n",
        "\n",
        "compare_agents(env_factory, [MyVacuumAgent], 100000, 50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "141273-homework-1-vacuum-cleaner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}